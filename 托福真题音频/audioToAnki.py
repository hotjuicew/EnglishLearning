import whisper
import subprocess
import pandas as pd
import os
from difflib import SequenceMatcher

# ===================== 1. è¯»å–å®Œæ•´å¬åŠ›æ–‡æœ¬ =====================
def load_text(english_file, chinese_file):
    print("ğŸ“„ è¯»å–å®Œæ•´å¬åŠ›æ–‡æœ¬...")
    
    with open(english_file, "r", encoding="utf-8") as f:
        english_text = f.read().replace("\n", " ")  # **ä¸å†æŒ‰æ¢è¡Œåˆ†å¥ï¼Œæ•´åˆæˆä¸€ä¸ªé•¿æ–‡æœ¬**

    with open(chinese_file, "r", encoding="utf-8") as f:
        chinese_text = f.read().replace("\n", " ")  # **æ•´åˆæˆä¸€ä¸ªé•¿æ–‡æœ¬**

    print(f"âœ… åŠ è½½å®Œæˆï¼šè‹±æ–‡ {len(english_text)} å­—ç¬¦ï¼Œä¸­æ–‡ {len(chinese_text)} å­—ç¬¦")
    return english_text, chinese_text

# ===================== 2. è¿è¡Œ Whisper è¯†åˆ«éŸ³é¢‘ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰ =====================
def transcribe_audio(audio_file):
    print("ğŸ” è¿è¡Œ Whisper è¯†åˆ«å®Œæ•´éŸ³é¢‘ï¼ˆä¼˜åŒ–åˆ†å¥ï¼Œè®©æ¯å¥è¯å°½é‡é•¿ï¼‰...")
    model = whisper.load_model("medium")

    result = model.transcribe(
        audio_file,
        word_timestamps=True,  
        language="en",
        temperature=0.0,
        best_of=5,  # é€‰æ‹©æœ€å¥½çš„ç»“æœï¼Œé¿å…çŸ­å¥
        compression_ratio_threshold=3.5,  # é˜²æ­¢è¿‡åº¦æ–­å¥
        no_speech_threshold=0.3,  # å…è®¸ä¸€å®šçš„æ— å£°æ—¶é—´ï¼Œå‡å°‘ä¸å¿…è¦çš„æ‹†åˆ†
        logprob_threshold=-1.0  # é™ä½é—¨æ§›ï¼Œç¡®ä¿å®Œæ•´å¥å­
    )

    whisper_sentences = [seg["text"] for seg in result["segments"]]
    timestamps = [(seg["start"], seg["end"]) for seg in result["segments"]]

    print(f"âœ… Whisper è¯†åˆ«å®Œæˆï¼Œç”Ÿæˆ {len(whisper_sentences)} å¥")
    return whisper_sentences, timestamps

# ===================== 3. åŒ¹é… Whisper ç»“æœå’Œ `english.txt` `chinese.txt` =====================
def match_texts(whisper_sentences, english_text, chinese_text):
    print("ğŸ”„ æ­£åœ¨åŒ¹é… `whisper_sentences` å¥å­...")

    matched_english = []
    matched_chinese = []

    for whisper_sentence in whisper_sentences:
        # æ‰¾åˆ° `english_text` é‡Œæœ€åŒ¹é…çš„ç‰‡æ®µ
        best_match_index = max(
            range(len(english_text) - len(whisper_sentence)),
            key=lambda i: SequenceMatcher(None, english_text[i:i+len(whisper_sentence)], whisper_sentence).ratio()
        )
        best_match_english = english_text[best_match_index:best_match_index+len(whisper_sentence)]

        # **æ‰¾åˆ°å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘**
        best_match_chinese_index = max(
            range(len(chinese_text) - len(best_match_english)),
            key=lambda i: SequenceMatcher(None, chinese_text[i:i+len(best_match_english)], best_match_english).ratio()
        )
        best_match_chinese = chinese_text[best_match_chinese_index:best_match_chinese_index+len(best_match_english)]

        matched_english.append(best_match_english)
        matched_chinese.append(best_match_chinese)

    print(f"âœ… åŒ¹é…å®Œæˆï¼Œæ‰€æœ‰ `whisper_sentences` å‡æ‰¾åˆ°å¯¹åº”æ–‡æœ¬")
    return matched_english, matched_chinese

# ===================== 4. ä½¿ç”¨ FFmpeg è£å‰ªéŸ³é¢‘ =====================
def split_audio(audio_file, timestamps, output_folder="audio_clips"):
    print("âœ‚ï¸  å¼€å§‹å‰ªè¾‘éŸ³é¢‘...")
    os.makedirs(output_folder, exist_ok=True)
    audio_files = []

    for i, (start, end) in enumerate(timestamps):
        output_file = f"{output_folder}/sentence_{i+1}.mp3"
        command = f'ffmpeg -i "{audio_file}" -ss {start} -to {end} -q:a 0 -map a "{output_file}" -y'
        subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        audio_files.append(output_file)
        print(f"ğŸ§ å‰ªè¾‘å®Œæˆï¼š{output_file}")

    print(f"âœ… æ‰€æœ‰éŸ³é¢‘å‰ªè¾‘å®Œæˆï¼Œå…± {len(audio_files)} å¥")
    return audio_files

# ===================== 5. ç”Ÿæˆ Anki CSV æ–‡ä»¶ =====================
def create_anki_csv(whisper_sentences, matched_english, matched_chinese, audio_files, output_csv="anki_listening_deck.csv"):
    print("ğŸ“„  ç”Ÿæˆ Anki CSV æ–‡ä»¶...")
    
    data = [
        ("[sound:" + os.path.basename(audio) + "]", whisper_text + "<br><br>" + english_text + "<br><br>" + chinese_text)
        for whisper_text, english_text, chinese_text, audio in zip(whisper_sentences, matched_english, matched_chinese, audio_files)
    ]

    df = pd.DataFrame(data, columns=["Front", "Back"])
    df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print(f"âœ… Anki CSV æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_csv}")
    return output_csv

# ===================== 6. ä¸»ç¨‹åºæ‰§è¡Œ =====================
def main():
    audio_file = "æ‰˜ç¦çœŸé¢˜35Passage2.mp3"  # ä½ çš„æ‰˜ç¦å¬åŠ›éŸ³é¢‘
    english_file = "english.txt"  # ä½ çš„å®Œæ•´è‹±æ–‡æ–‡æœ¬
    chinese_file = "chinese.txt"  # ä½ çš„å®Œæ•´ä¸­æ–‡æ–‡æœ¬
    output_folder = "audio_clips"

    # è¯»å–å®Œæ•´æ–‡æœ¬ï¼ˆä¸æŒ‰æ¢è¡Œæ‹†åˆ†ï¼‰
    english_text, chinese_text = load_text(english_file, chinese_file)

    # è¿è¡Œ Whisperï¼Œè·å–å®Œæ•´éŸ³é¢‘ + é€è¯æ—¶é—´æˆ³
    whisper_sentences, timestamps = transcribe_audio(audio_file)

    # è®© `whisper_sentences` å¯¹é½ `english.txt` å’Œ `chinese.txt`
    matched_english, matched_chinese = match_texts(whisper_sentences, english_text, chinese_text)

    # è£å‰ªéŸ³é¢‘
    audio_files = split_audio(audio_file, timestamps, output_folder)

    # ç”Ÿæˆ Anki CSV
    csv_file = create_anki_csv(whisper_sentences, matched_english, matched_chinese, audio_files)

    print("\nğŸš€ **æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼è¯·å°†ä»¥ä¸‹æ–‡ä»¶å¯¼å…¥ Ankiï¼š**")
    print(f"ğŸ“‚ {csv_file} ï¼ˆå¡ç‰‡æ•°æ®ï¼‰")
    print(f"ğŸ“‚ {output_folder}/  ï¼ˆæ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œéœ€æ”¾å…¥ Anki media ç›®å½•ï¼‰")

if __name__ == "__main__":
    main()
