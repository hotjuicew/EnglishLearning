import whisper
import subprocess
import pandas as pd
import os
from difflib import SequenceMatcher
from googletrans import Translator  # è‡ªåŠ¨ç¿»è¯‘

# ===================== 1. è¯»å– `english.txt` =====================
def load_english_text(english_file):
    print("ğŸ“„ è¯»å– `english.txt` ä½œä¸ºä¸€æ•´æ®µæ–‡æœ¬...")
    with open(english_file, "r", encoding="utf-8") as f:
        english_text = f.read().replace("\n", " ")  # **æ•´åˆä¸ºä¸€æ•´æ®µæ–‡æœ¬**
    
    print(f"âœ… åŠ è½½å®Œæˆï¼Œæ€»å­—ç¬¦æ•°ï¼š{len(english_text)}")
    return english_text

# ===================== 2. è¿è¡Œ Whisper è¯†åˆ«éŸ³é¢‘ï¼ˆè·å–æ—¶é—´æˆ³ï¼‰ =====================
def transcribe_audio(audio_file):
    print("ğŸ” è¿è¡Œ Whisper è¯†åˆ«å®Œæ•´éŸ³é¢‘ï¼ˆç²¾å‡†åˆ†å¥ï¼‰...")
    model = whisper.load_model("medium")

    result = model.transcribe(
        audio_file,
        word_timestamps=True,  
        language="en",
        temperature=0.0,
        best_of=5,  
        compression_ratio_threshold=3.5,  
        no_speech_threshold=0.3,  
        logprob_threshold=-1.0  
    )

    whisper_sentences = [seg["text"] for seg in result["segments"]]
    timestamps = [(seg["start"], seg["end"]) for seg in result["segments"]]

    print(f"âœ… Whisper è¯†åˆ«å®Œæˆï¼Œç”Ÿæˆ {len(whisper_sentences)} å¥")
    return whisper_sentences, timestamps

# ===================== 3. æ™ºèƒ½åŒ¹é… `english.txt` å¥å­ =====================
def match_text_with_whisper(whisper_sentences, english_text):
    print("ğŸ”„ æ ¹æ® Whisper åˆ†å¥åŒ¹é… `english.txt` å†…å®¹...")
    matched_english = []

    # éå† Whisper è¯†åˆ«çš„æ¯ä¸€å¥ï¼Œæ‰¾åˆ° `english_text` ä¸­æœ€åŒ¹é…çš„ç‰‡æ®µ
    for whisper_sentence in whisper_sentences:
        best_match_index = max(
            range(len(english_text) - len(whisper_sentence)),
            key=lambda i: SequenceMatcher(None, english_text[i:i+len(whisper_sentence)], whisper_sentence).ratio()
        )
        best_match_english = english_text[best_match_index:best_match_index+len(whisper_sentence)]
        matched_english.append(best_match_english)

    print(f"âœ… åŒ¹é…å®Œæˆï¼Œå…± {len(matched_english)} å¥")
    return matched_english

# ===================== 4. è‡ªåŠ¨ç¿»è¯‘è‹±æ–‡åˆ°ä¸­æ–‡ =====================
def translate_to_chinese(english_sentences):
    print("ğŸŒ è‡ªåŠ¨ç¿»è¯‘ `english.txt` å¥å­åˆ°ä¸­æ–‡...")
    translator = Translator()
    chinese_sentences = []

    for sentence in english_sentences:
        translation = translator.translate(sentence, src="en", dest="zh-cn").text
        chinese_sentences.append(translation)
        print(f"ğŸ”¹ {sentence} â†’ {translation}")

    print(f"âœ… ç¿»è¯‘å®Œæˆï¼Œå…± {len(chinese_sentences)} å¥")
    return chinese_sentences

# ===================== 5. ä½¿ç”¨ FFmpeg è£å‰ªéŸ³é¢‘ =====================
def split_audio(audio_file, timestamps, output_folder="audio_clips"):
    print("âœ‚ï¸  å¼€å§‹å‰ªè¾‘éŸ³é¢‘...")
    os.makedirs(output_folder, exist_ok=True)
    audio_files = []

    for i, (start, end) in enumerate(timestamps):
        output_file = f"{output_folder}/{audio_file}_{i+1}.mp3"
        command = f'ffmpeg -i "{audio_file}" -ss {start} -to {end} -q:a 0 -map a "{output_file}" -y'
        subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        audio_files.append(output_file)
        print(f"ğŸ§ å‰ªè¾‘å®Œæˆï¼š{output_file}")

    print(f"âœ… æ‰€æœ‰éŸ³é¢‘å‰ªè¾‘å®Œæˆï¼Œå…± {len(audio_files)} å¥")
    return audio_files

# ===================== 6. ç”Ÿæˆ Anki CSV æ–‡ä»¶ =====================
def create_anki_csv(matched_english, chinese_sentences, audio_files, output_csv="anki_listening_deck.csv"):
    print("ğŸ“„  ç”Ÿæˆ Anki CSV æ–‡ä»¶...")
    
    data = [
        ("[sound:" + os.path.basename(audio) + "]", english_text + "<br><br>" + chinese_text)
        for english_text, chinese_text, audio in zip(matched_english, chinese_sentences, audio_files)
    ]

    df = pd.DataFrame(data, columns=["Front", "Back"])
    df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print(f"âœ… Anki CSV æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_csv}")
    return output_csv

# ===================== 7. ä¸»ç¨‹åºæ‰§è¡Œ =====================
def main():
    audio_file = "æ‰˜ç¦çœŸé¢˜35Passage2.mp3"  
    english_file = "english.txt"  
    output_folder = "audio_clips"

    # è¯»å– `english.txt` ä½œä¸ºä¸€æ•´æ®µ
    english_text = load_english_text(english_file)

    # è¿è¡Œ Whisperï¼Œè·å–æ—¶é—´æˆ³
    whisper_sentences, timestamps = transcribe_audio(audio_file)

    # æ ¹æ® Whisper è¯†åˆ«çš„åˆ†å¥ï¼Œåœ¨ `english.txt` é‡Œæ‰¾åˆ°æœ€åŒ¹é…çš„å†…å®¹
    matched_english = match_text_with_whisper(whisper_sentences, english_text)

    # è‡ªåŠ¨ç¿»è¯‘æˆä¸­æ–‡
    chinese_sentences = translate_to_chinese(matched_english)

    # è£å‰ªéŸ³é¢‘
    audio_files = split_audio(audio_file, timestamps, output_folder)

    # ç”Ÿæˆ Anki CSV
    csv_file = create_anki_csv(matched_english, chinese_sentences, audio_files)

    print("\nğŸš€ **æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼è¯·å°†ä»¥ä¸‹æ–‡ä»¶å¯¼å…¥ Ankiï¼š**")
    print(f"ğŸ“‚ {csv_file} ï¼ˆå¡ç‰‡æ•°æ®ï¼‰")
    print(f"ğŸ“‚ {output_folder}/  ï¼ˆæ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œéœ€æ”¾å…¥ Anki media ç›®å½•ï¼‰")

if __name__ == "__main__":
    main()
