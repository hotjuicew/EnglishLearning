import whisper
import subprocess
import pandas as pd
import os
import re
from difflib import SequenceMatcher

# ===================== 1. è¯»å–å®Œæ•´å¬åŠ›æ–‡æœ¬ï¼ˆæå–è‹±æ–‡å’Œä¸­æ–‡ï¼‰ =====================
def load_full_text(text_file):
    print("ğŸ“„ è¯»å–å®Œæ•´å¬åŠ›æ–‡æœ¬...")
    english_sentences = []
    chinese_sentences = []

    with open(text_file, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f.readlines() if line.strip()]

    for i in range(0, len(lines), 2):  # æ¯ä¸¤è¡Œæ˜¯ä¸€ç»„ï¼ˆè‹±æ–‡ + ä¸­æ–‡ï¼‰
        if i + 1 < len(lines):
            english_sentences.append(lines[i])
            chinese_sentences.append(lines[i + 1])

    print(f"âœ… åŠ è½½å®Œæˆï¼šè‹±æ–‡ {len(english_sentences)} å¥ï¼Œä¸­æ–‡ {len(chinese_sentences)} å¥")
    return english_sentences, chinese_sentences

# ===================== 2. è¿è¡Œ Whisper è·å–æ—¶é—´æˆ³ =====================
def transcribe_audio(audio_file, english_sentences):
    print("ğŸ” è¿è¡Œ Whisper è·å–æ—¶é—´æˆ³ï¼ˆå¼ºåˆ¶åŒ¹é…è‹±æ–‡æ–‡æœ¬ï¼‰...")
    model = whisper.load_model("medium")

    result = model.transcribe(
        audio_file,
        word_timestamps=True,
        language="en",
        initial_prompt="\n".join(english_sentences),  # è®© Whisper å‚è€ƒå®Œæ•´è‹±æ–‡æ–‡æœ¬
        temperature=0.0,
        compression_ratio_threshold=3.0
    )

    whisper_sentences = [seg["text"] for seg in result["segments"]]
    timestamps = [(seg["start"], seg["end"]) for seg in result["segments"]]

    # ç¡®ä¿ Whisper è¯†åˆ«å‡ºçš„æ–‡æœ¬å’Œ `full_text.txt` è¿›è¡Œå¯¹é½
    aligned_sentences = align_sentences(whisper_sentences, english_sentences)

    print(f"âœ… è·å–æ—¶é—´æˆ³å®Œæˆï¼Œå…± {len(timestamps)} æ®µ")
    return timestamps[:len(aligned_sentences)], aligned_sentences

# ===================== 3. åŒ¹é… Whisper å¥å­å’Œ `full_text.txt` =====================
def align_sentences(whisper_sentences, full_text_sentences):
    aligned_sentences = []
    
    for full_text in full_text_sentences:
        best_match = max(whisper_sentences, key=lambda x: SequenceMatcher(None, x, full_text).ratio())
        aligned_sentences.append(best_match)

    return aligned_sentences

# ===================== 4. ä½¿ç”¨ FFmpeg è£å‰ªéŸ³é¢‘ =====================
def split_audio(audio_file, timestamps, output_folder="audio_clips"):
    print("âœ‚ï¸  å¼€å§‹å‰ªè¾‘éŸ³é¢‘...")
    os.makedirs(output_folder, exist_ok=True)
    audio_files = []

    for i, (start, end) in enumerate(timestamps):
        output_file = f"{output_folder}/{audio_file}_{i+1}.mp3"
        command = f'ffmpeg -i "{audio_file}" -ss {start} -to {end} -q:a 0 -map a "{output_file}" -y'
        subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        audio_files.append(output_file)
        print(f"ğŸ§ å‰ªè¾‘å®Œæˆï¼š{output_file}")

    print(f"âœ… æ‰€æœ‰éŸ³é¢‘å‰ªè¾‘å®Œæˆï¼Œå…± {len(audio_files)} å¥")
    return audio_files

# ===================== 5. ç”Ÿæˆ Anki CSV æ–‡ä»¶ =====================
def create_anki_csv(english_sentences, chinese_sentences, audio_files, output_csv="anki_listening_deck.csv"):
    print("ğŸ“„  ç”Ÿæˆ Anki CSV æ–‡ä»¶...")
    
    # æ­£é¢æ˜¯éŸ³é¢‘ï¼ŒèƒŒé¢æ˜¯è‹±æ–‡ + ä¸­æ–‡ç¿»è¯‘
    data = [
        ("[sound:" + os.path.basename(audio) + "]", english + "<br><br>" + chinese)
        for english, chinese, audio in zip(english_sentences, chinese_sentences, audio_files)
    ]

    df = pd.DataFrame(data, columns=["Front", "Back"])
    df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print(f"âœ… Anki CSV æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_csv}")
    return output_csv

# ===================== 6. ä¸»ç¨‹åºæ‰§è¡Œ =====================
def main():
    audio_file = "æ‰˜ç¦100çœŸé¢˜3C1.mp3"
    text_file = "full_text.txt"
    output_folder = "audio_clips"

    # è¯»å–å®Œæ•´æ–‡æœ¬ï¼ˆæå–è‹±æ–‡å’Œä¸­æ–‡ï¼‰
    english_sentences, chinese_sentences = load_full_text(text_file)

    # è¿è¡Œ Whisper è·å–æ—¶é—´æˆ³ï¼Œå¹¶åŒ¹é…å®Œæ•´è‹±æ–‡æ–‡æœ¬
    timestamps, aligned_sentences = transcribe_audio(audio_file, english_sentences)

    # ç¡®ä¿æ—¶é—´æˆ³å’Œæ–‡æœ¬åŒ¹é…
    if len(aligned_sentences) != len(timestamps):
        print(f"âš ï¸ è­¦å‘Šï¼šæ–‡æœ¬å¥æ•° ({len(aligned_sentences)}) ä¸ Whisper è¯†åˆ«çš„æ—¶é—´æˆ³æ•° ({len(timestamps)}) ä¸åŒ¹é…ï¼")
        print("ğŸ” è¯·æ£€æŸ¥ full_text.txt æ˜¯å¦ä¸éŸ³é¢‘å¯¹åº”ï¼Œæˆ–æ‰‹åŠ¨è°ƒæ•´æ—¶é—´æˆ³ï¼")
        return

    # è£å‰ªéŸ³é¢‘
    audio_files = split_audio(audio_file, timestamps, output_folder)

    # ç”Ÿæˆ Anki CSV
    csv_file = create_anki_csv(english_sentences, chinese_sentences, audio_files)

    print("\nğŸš€ **æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼è¯·å°†ä»¥ä¸‹æ–‡ä»¶å¯¼å…¥ Ankiï¼š**")
    print(f"ğŸ“‚ {csv_file} ï¼ˆå¡ç‰‡æ•°æ®ï¼‰")
    print(f"ğŸ“‚ {output_folder}/  ï¼ˆæ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œéœ€æ”¾å…¥ Anki media ç›®å½•ï¼‰")

if __name__ == "__main__":
    main()
