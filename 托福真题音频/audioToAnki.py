import whisper
import subprocess
import pandas as pd
import os
from difflib import SequenceMatcher
from googletrans import Translator  # è‡ªåŠ¨ç¿»è¯‘

# ===================== 1. è¯»å– `english.txt` =====================
def load_english_text(english_file):
    print("ğŸ“„ è¯»å– `english.txt` ä½œä¸ºä¸€æ•´æ®µæ–‡æœ¬...")
    with open(english_file, "r", encoding="utf-8") as f:
        english_text = f.read().replace("\n", " ").replace("  ", "")  # **æ•´åˆä¸ºä¸€æ•´æ®µæ–‡æœ¬**
    
    print(f"âœ… åŠ è½½å®Œæˆï¼Œæ€»å­—ç¬¦æ•°ï¼š{len(english_text)}")
    return english_text

# ===================== 2. è¿è¡Œ Whisper è¯†åˆ«éŸ³é¢‘ï¼ˆä¼˜åŒ–æ–­å¥ï¼‰ =====================
def transcribe_audio(audio_file):
    print("ğŸ” è¿è¡Œ Whisper è¯†åˆ«å®Œæ•´éŸ³é¢‘ï¼ˆå‡å°‘æ–­å¥é¢‘ç‡ï¼‰...")
    model = whisper.load_model("medium")

    result = model.transcribe(
        audio_file,
        word_timestamps=True,  
        language="en",
        temperature=0.1,  # ä½æ¸©åº¦ï¼Œé¿å…ä¹±æ–­å¥
        best_of=5,  
        compression_ratio_threshold=4.0,  # æé«˜å‹ç¼©æ¯”ï¼Œå‡å°‘æ–­å¥
        no_speech_threshold=0.5,  # å¿½ç•¥çŸ­æš‚åœé¡¿
        logprob_threshold=-2.0,  # å…è®¸æ›´ä½ç½®ä¿¡åº¦çš„å¥å­ï¼Œä¸è¦å¼ºè¡Œåˆ†æ®µ
        condition_on_previous_text=False  # è®© Whisper åªè€ƒè™‘å½“å‰å¥å­ï¼Œå‡å°‘çŸ­å¥
    )

    whisper_sentences = [seg["text"] for seg in result["segments"]]
    timestamps = [(seg["start"], seg["end"]) for seg in result["segments"]]

    print(f"âœ… Whisper è¯†åˆ«å®Œæˆï¼Œç”Ÿæˆ {len(whisper_sentences)} å¥")
    return whisper_sentences, timestamps

# ===================== 3. åˆå¹¶çŸ­å¥ =====================
def merge_short_sentences(whisper_sentences, timestamps, min_duration=0.5, max_merge=3):
    print("ğŸ”„ åˆå¹¶çŸ­å¥ï¼Œå‡å°‘æ–­å¥...")
    merged_sentences = []
    merged_timestamps = []

    i = 0
    while i < len(whisper_sentences):
        current_sentence = whisper_sentences[i]
        start_time = timestamps[i][0]
        end_time = timestamps[i][1]
        merge_count = 0  # è®°å½•åˆå¹¶æ¬¡æ•°ï¼Œé¿å…è¶…é™

        # å¦‚æœä¸‹ä¸€ä¸ªå¥å­çš„é—´éš”å¾ˆçŸ­ï¼Œå°±åˆå¹¶
        while (
            i + 1 < len(whisper_sentences) and 
            (timestamps[i + 1][0] - end_time) < min_duration and 
            merge_count < max_merge  # é™åˆ¶æœ€å¤§åˆå¹¶æ¬¡æ•°
        ):
            current_sentence += " " + whisper_sentences[i + 1]
            end_time = timestamps[i + 1][1]
            i += 1  # è·³è¿‡åˆå¹¶çš„å¥å­
            merge_count += 1  # è®¡æ•°

        merged_sentences.append(current_sentence)
        merged_timestamps.append((start_time, end_time))
        i += 1  # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæœªåˆå¹¶çš„å¥å­

    print(f"âœ… åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆä¿ç•™ {len(merged_sentences)} å¥")
    return merged_sentences, merged_timestamps


# ===================== 4. æ™ºèƒ½åŒ¹é… `english.txt` å¥å­ =====================
def match_text_with_whisper(whisper_sentences, english_text):
    print("ğŸ”„ æ ¹æ® Whisper åˆ†å¥åŒ¹é… `english.txt` å†…å®¹...")
    matched_english = []

    for whisper_sentence in whisper_sentences:
        best_match_index = max(
            range(len(english_text) - len(whisper_sentence)),
            key=lambda i: SequenceMatcher(None, english_text[i:i+len(whisper_sentence)], whisper_sentence).ratio()
        )
        best_match_english = english_text[best_match_index:best_match_index+len(whisper_sentence)]
        matched_english.append(best_match_english)

    print(f"âœ… åŒ¹é…å®Œæˆï¼Œå…± {len(matched_english)} å¥")
    return matched_english

# ===================== 5. è‡ªåŠ¨ç¿»è¯‘è‹±æ–‡åˆ°ä¸­æ–‡ =====================
def translate_to_chinese(english_sentences):
    print("ğŸŒ è‡ªåŠ¨ç¿»è¯‘ `english.txt` å¥å­åˆ°ä¸­æ–‡...")
    translator = Translator()
    chinese_sentences = []

    for sentence in english_sentences:
        translation = translator.translate(sentence, src="en", dest="zh-cn").text
        chinese_sentences.append(translation)
        print(f"ğŸ”¹ {sentence} â†’ {translation}")

    print(f"âœ… ç¿»è¯‘å®Œæˆï¼Œå…± {len(chinese_sentences)} å¥")
    return chinese_sentences

# ===================== 6. ä½¿ç”¨ FFmpeg è£å‰ªéŸ³é¢‘ =====================
def split_audio(audio_file, timestamps, output_folder="audio_clips"):
    print("âœ‚ï¸  å¼€å§‹å‰ªè¾‘éŸ³é¢‘...")
    os.makedirs(output_folder, exist_ok=True)
    audio_files = []

    for i, (start, end) in enumerate(timestamps):
        output_file = f"{output_folder}/{audio_file.replace('.mp3', '')}_{i+1}.mp3"
        command = f'ffmpeg -i "{audio_file}" -ss {start} -to {end} -q:a 0 -map a "{output_file}" -y'
        subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        audio_files.append(output_file)
        print(f"ğŸ§ å‰ªè¾‘å®Œæˆï¼š{output_file}")

    print(f"âœ… æ‰€æœ‰éŸ³é¢‘å‰ªè¾‘å®Œæˆï¼Œå…± {len(audio_files)} å¥")
    return audio_files

# ===================== 7. ç”Ÿæˆ Anki CSV æ–‡ä»¶ =====================
def create_anki_csv(matched_english, chinese_sentences, audio_files, output_csv="anki_listening_deck.csv"):
    print("ğŸ“„  ç”Ÿæˆ Anki CSV æ–‡ä»¶...")
    
    data = [
        ("[sound:" + os.path.basename(audio) + "]", english_text + "<br><br>" + chinese_text)
        for english_text, chinese_text, audio in zip(matched_english, chinese_sentences, audio_files)
    ]

    df = pd.DataFrame(data, columns=["Front", "Back"])
    df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print(f"âœ… Anki CSV æ–‡ä»¶å·²ç”Ÿæˆï¼š{output_csv}")
    return output_csv

# ===================== 8. ä¸»ç¨‹åºæ‰§è¡Œ =====================
def main():
    audio_file = "æ‰˜ç¦çœŸé¢˜36Passage1.mp3"  
    english_file = "english.txt"  
    output_folder = "audio_clips"

    print(f"âš ï¸ å³å°†å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼š{audio_file}")
    confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(Y/N): ").strip().lower()

    if confirm != "y":
        print("âŒ ä»»åŠ¡å·²å–æ¶ˆã€‚")
        return

    print("âœ… ç¡®è®¤ç»§ç»­ï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘...")

    # è¯»å– `english.txt` ä½œä¸ºä¸€æ•´æ®µ
    english_text = load_english_text(english_file)

    # è¿è¡Œ Whisperï¼Œè·å–æ—¶é—´æˆ³
    whisper_sentences, timestamps = transcribe_audio(audio_file)

    # åˆå¹¶çŸ­å¥ï¼Œå‡å°‘æ–­å¥
    merged_sentences, merged_timestamps = merge_short_sentences(whisper_sentences, timestamps)

    # æ ¹æ® Whisper è¯†åˆ«çš„åˆ†å¥ï¼Œåœ¨ `english.txt` é‡Œæ‰¾åˆ°æœ€åŒ¹é…çš„å†…å®¹
    matched_english = match_text_with_whisper(merged_sentences, english_text)

    # è‡ªåŠ¨ç¿»è¯‘æˆä¸­æ–‡
    chinese_sentences = translate_to_chinese(matched_english)

    # è£å‰ªéŸ³é¢‘
    audio_files = split_audio(audio_file, merged_timestamps, output_folder)

    # ç”Ÿæˆ Anki CSV
    csv_file = create_anki_csv(matched_english, chinese_sentences, audio_files)

if __name__ == "__main__":
    main()
